{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0akwlVG4Dw0",
        "outputId": "a9ff161a-c5c8-4425-d56c-1558afce2efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komórka 1: Biblioteki zaimportowane, funkcja generująca dane zdefiniowana.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Definicja funkcji generującej dane\n",
        "def generate_vet_eye_data(num_records=1000):\n",
        "    \"\"\"Generuje syntetyczny DataFrame dla Vet-Eye CRM.\"\"\"\n",
        "    segment_options = [\"klinika\", \"mobilny\", \"szpital\"]\n",
        "    segment_weights = [0.6, 0.2, 0.2] # Przykładowe wagi dla segmentów\n",
        "    data = []\n",
        "    for i in range(1, num_records + 1):\n",
        "        client_id = f\"CL-{i:04d}\"\n",
        "        segment = random.choices(segment_options, weights=segment_weights, k=1)[0]\n",
        "\n",
        "        if segment == \"mobilny\":\n",
        "            clinic_size = random.randint(1, 2)\n",
        "            devices_owned = random.randint(1, 2)\n",
        "        elif segment == \"klinika\":\n",
        "            clinic_size = random.randint(2, 15)\n",
        "            devices_owned = random.randint(1, 4)\n",
        "        else:  # szpital\n",
        "            clinic_size = random.randint(10, 50)\n",
        "            devices_owned = random.randint(2, 8)\n",
        "\n",
        "        last_purchase_days_ago = random.randint(7, 730)\n",
        "        purchase_count = random.randint(1, 30)\n",
        "        avg_purchase_value = round(random.uniform(500.0, 15000.0), 2)\n",
        "\n",
        "        tu2_active = random.choices([0, 1], weights=[0.3, 0.7], k=1)[0]\n",
        "\n",
        "        if tu2_active == 1:\n",
        "            tu2_sessions_last_30d = random.randint(0, 200)\n",
        "            ai_usage_ratio = round(random.uniform(0.0, 1.0), 2)\n",
        "        else:\n",
        "            tu2_sessions_last_30d = 0\n",
        "            ai_usage_ratio = 0.0\n",
        "\n",
        "        last_contact_days_ago = random.randint(1, 365)\n",
        "        open_rate = round(random.uniform(0.05, 0.9), 2)\n",
        "        click_rate = round(random.uniform(0.0, open_rate * 0.5), 2)\n",
        "        support_tickets_last_6m = random.randint(0, 10)\n",
        "\n",
        "        buy_chance = 0.1\n",
        "        if 30 < last_purchase_days_ago < 180: buy_chance += 0.1\n",
        "        if tu2_sessions_last_30d > 50: buy_chance += 0.1\n",
        "        if avg_purchase_value > 5000: buy_chance += 0.05\n",
        "        buy_label = 1 if random.random() < buy_chance else 0\n",
        "\n",
        "        churn_chance = 0.05\n",
        "        if support_tickets_last_6m > 5: churn_chance += 0.1\n",
        "        if tu2_active == 1 and tu2_sessions_last_30d < 10: churn_chance += 0.05\n",
        "        if last_contact_days_ago > 180: churn_chance += 0.1\n",
        "        if not tu2_active: churn_chance += 0.1\n",
        "        churn_label = 1 if random.random() < min(churn_chance, 0.8) else 0\n",
        "\n",
        "        if buy_label == 1 and churn_label == 1:\n",
        "            if random.random() < 0.7: churn_label = 0\n",
        "        if tu2_active == 0 and last_purchase_days_ago > 180 :\n",
        "            if random.random() < 0.3 : churn_label = 1\n",
        "\n",
        "        data.append([\n",
        "            client_id, segment, clinic_size, devices_owned,\n",
        "            last_purchase_days_ago, purchase_count, avg_purchase_value,\n",
        "            tu2_active, tu2_sessions_last_30d, ai_usage_ratio,\n",
        "            last_contact_days_ago, open_rate, click_rate,\n",
        "            support_tickets_last_6m, buy_label, churn_label\n",
        "        ])\n",
        "\n",
        "    columns = [\n",
        "        \"client_id\", \"segment\", \"clinic_size\", \"devices_owned\",\n",
        "        \"last_purchase_days_ago\", \"purchase_count\", \"avg_purchase_value\",\n",
        "        \"tu2_active\", \"tu2_sessions_last_30d\", \"ai_usage_ratio\",\n",
        "        \"last_contact_days_ago\", \"open_rate\", \"click_rate\",\n",
        "        \"support_tickets_last_6m\", \"buy_label\", \"churn_label\"\n",
        "    ]\n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "print(\"Komórka 1: Biblioteki zaimportowane, funkcja generująca dane zdefiniowana.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Konfiguracja Globalna ---\n",
        "DATA_FILE_NAME = \"vet_eye_crm_data_1000_PL.csv\"\n",
        "MODEL_UPSELL_FILE = \"model_upsell.json\"\n",
        "MODEL_CHURN_FILE = \"model_churn.json\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "print(\"Komórka 2: Generowanie danych syntetycznych (1000 rekordów)...\")\n",
        "df_global = generate_vet_eye_data(num_records=1000)\n",
        "\n",
        "df_global.to_csv(DATA_FILE_NAME, index=False, encoding='utf-8')\n",
        "print(f\"Dane wygenerowane i zapisane do '{DATA_FILE_NAME}' (w środowisku Colab).\")\n",
        "print(f\"Liczba rekordów: {len(df_global)}\")\n",
        "\n",
        "X_source_global = df_global.drop(['client_id', 'buy_label', 'churn_label'], axis=1)\n",
        "y_upsell_source_global = df_global['buy_label']\n",
        "y_churn_source_global = df_global['churn_label']\n",
        "\n",
        "categorical_features_global = ['segment']\n",
        "\n",
        "preprocessor_global = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_global)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "print(\"Dane przygotowane i zmienne globalne zdefiniowane.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2aSWhWx4SAt",
        "outputId": "a4bc5acc-ebe4-49ea-87f0-400bebcfab68"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komórka 2: Generowanie danych syntetycznych (1000 rekordów)...\n",
            "Dane wygenerowane i zapisane do 'vet_eye_crm_data_1000_PL.csv' (w środowisku Colab).\n",
            "Liczba rekordów: 1000\n",
            "Dane przygotowane i zmienne globalne zdefiniowane.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "def train_evaluate_model_generic(model_type_name, X_full, y_full, preprocessor_to_use, cat_features_list, model_output_filename):\n",
        "    print(f\"\\n--- Rozpoczęcie Pracy nad Modelem: {model_type_name} ---\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_full, y_full, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_full\n",
        "    )\n",
        "\n",
        "    print(f\"Rozmiar zbioru treningowego: {X_train.shape[0]}, Rozmiar zbioru testowego: {X_test.shape[0]}\")\n",
        "\n",
        "    current_preprocessor = clone(preprocessor_to_use)\n",
        "\n",
        "    X_train_processed = current_preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = current_preprocessor.transform(X_test)\n",
        "\n",
        "    # Próba pobrania nazw cech po transformacji\n",
        "    # Ta część może być wrażliwa na wersje sklearn, staramy się być elastyczni\n",
        "    processed_feature_names = None\n",
        "    try:\n",
        "        processed_feature_names = list(current_preprocessor.get_feature_names_out())\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            # Starsza metoda dla OneHotEncoder w ColumnTransformer\n",
        "            ohe_feature_names = list(current_preprocessor.named_transformers_['onehot'].get_feature_names_out(cat_features_list))\n",
        "            # Nazwy cech, które przeszły przez 'passthrough'\n",
        "            num_feature_names_indices = [i for i, t in enumerate(current_preprocessor.transformers_) if t[0] == 'remainder' and t[1] == 'passthrough'][0][2]\n",
        "            remainder_feature_names = [X_full.columns[i] for i in num_feature_names_indices]\n",
        "            processed_feature_names = ohe_feature_names + remainder_feature_names\n",
        "        except Exception as e:\n",
        "            print(f\"Ostrzeżenie: Nie udało się automatycznie pobrać nazw cech po transformacji: {e}\")\n",
        "            print(\"Model XGBoost zostanie wytrenowany bez jawnie zdefiniowanych nazw cech.\")\n",
        "            # W takim przypadku XGBoost sam sobie poradzi, ale może wyświetlić ostrzeżenie, jeśli nazwy będą potrzebne później\n",
        "            # np. przy SHAP values. Dla samego treningu i predykcji nie jest to krytyczne.\n",
        "\n",
        "    if processed_feature_names and len(processed_feature_names) != X_train_processed.shape[1]:\n",
        "        print(f\"Ostrzeżenie: Niezgodność liczby nazw cech ({len(processed_feature_names)}) z liczbą kolumn ({X_train_processed.shape[1]}). Użycie domyślnych nazw.\")\n",
        "        processed_feature_names = None\n",
        "\n",
        "\n",
        "    print(f\"Liczba cech po przetworzeniu dla {model_type_name}: {X_train_processed.shape[1]}\")\n",
        "    if processed_feature_names:\n",
        "        print(f\"Przykładowe przetworzone nazwy cech: {processed_feature_names[:5]}...\")\n",
        "    else:\n",
        "        print(\"Model będzie trenowany bez jawnie przekazanych nazw przetworzonych cech.\")\n",
        "\n",
        "\n",
        "    scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1) if np.sum(y_train == 1) > 0 else 1\n",
        "    print(f\"{model_type_name} - scale_pos_weight: {scale_pos_weight:.2f}\")\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        n_estimators=150,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=RANDOM_STATE,\n",
        "        use_label_encoder=False, # To jest ważne\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        eval_metric=['logloss', 'auc'], # POPRAWKA: eval_metric jest parametrem KONSTRUKTORA\n",
        "        early_stopping_rounds=20 # POPRAWKA: early_stopping_rounds jest parametrem KONSTRUKTORA\n",
        "    )\n",
        "\n",
        "    print(f\"Trening modelu {model_type_name}...\")\n",
        "    model.fit(\n",
        "        X_train_processed, y_train,\n",
        "        eval_set=[(X_test_processed, y_test)], # eval_set jest przekazywany do fit\n",
        "        verbose=False\n",
        "    )\n",
        "    print(\"Trening zakończony.\")\n",
        "\n",
        "    model.save_model(model_output_filename)\n",
        "    print(f\"Model {model_type_name} zapisany do pliku: {model_output_filename}\")\n",
        "\n",
        "    print(f\"\\nEwaluacja modelu {model_type_name} na zbiorze testowym (używając modelu z 'best_iteration'):\")\n",
        "    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
        "    y_pred_class = model.predict(X_test_processed)\n",
        "\n",
        "    # Sprawdzenie, czy atrybut best_iteration istnieje\n",
        "    if hasattr(model, 'best_iteration_') and model.best_iteration_ is not None: # W Scikit-learn API jest to best_iteration_\n",
        "         print(f\"  Najlepsza iteracja (0-indexed): {model.best_iteration_}\")\n",
        "    elif hasattr(model, 'best_iteration') and model.best_iteration is not None: # Dla pewności, jeśli API się zmieniło\n",
        "         print(f\"  Najlepsza iteracja (0-indexed): {model.best_iteration}\")\n",
        "    else:\n",
        "        print(\"  Wczesne zatrzymanie mogło się nie aktywować lub atrybut best_iteration nie jest dostępny w tej wersji/konfiguracji.\")\n",
        "\n",
        "    print(f\"  AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "    print(f\"  F1-Score: {f1_score(y_test, y_pred_class):.4f}\")\n",
        "    print(f\"  Precyzja: {precision_score(y_test, y_pred_class, zero_division=0):.4f}\")\n",
        "    print(f\"  Czułość (Recall): {recall_score(y_test, y_pred_class, zero_division=0):.4f}\")\n",
        "    print(\"  Macierz Pomyłek:\")\n",
        "    cm = confusion_matrix(y_test, y_pred_class)\n",
        "    print(cm)\n",
        "\n",
        "    print(f\"--- Koniec Pracy nad Modelem: {model_type_name} ---\")\n",
        "    return model\n",
        "\n",
        "print(\"Komórka 3: Funkcja do treningu i ewaluacji modelu POPRAWIONA (eval_metric i early_stopping_rounds w konstruktorze XGBClassifier).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28gteWKy4VG9",
        "outputId": "65f728df-4564-44c7-db38-72464be29ac0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komórka 3: Funkcja do treningu i ewaluacji modelu POPRAWIONA (eval_metric i early_stopping_rounds w konstruktorze XGBClassifier).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trening i ewaluacja modelu Upsell\n",
        "model_upsell = train_evaluate_model_generic(\n",
        "    model_type_name=\"Upsell (Buy Label)\",\n",
        "    X_full=X_source_global.copy(),\n",
        "    y_full=y_upsell_source_global,\n",
        "    preprocessor_to_use=preprocessor_global,\n",
        "    cat_features_list=categorical_features_global,\n",
        "    model_output_filename=MODEL_UPSELL_FILE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frskzjqA4Xz1",
        "outputId": "ed8dcd61-f084-45ca-9fac-5827ecec32f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Rozpoczęcie Pracy nad Modelem: Upsell (Buy Label) ---\n",
            "Rozmiar zbioru treningowego: 800, Rozmiar zbioru testowego: 200\n",
            "Liczba cech po przetworzeniu dla Upsell (Buy Label): 15\n",
            "Przykładowe przetworzone nazwy cech: ['onehot__segment_klinika', 'onehot__segment_mobilny', 'onehot__segment_szpital', 'remainder__clinic_size', 'remainder__devices_owned']...\n",
            "Upsell (Buy Label) - scale_pos_weight: 4.30\n",
            "Trening modelu Upsell (Buy Label)...\n",
            "Trening zakończony.\n",
            "Model Upsell (Buy Label) zapisany do pliku: model_upsell.json\n",
            "\n",
            "Ewaluacja modelu Upsell (Buy Label) na zbiorze testowym (używając modelu z 'best_iteration'):\n",
            "  Najlepsza iteracja (0-indexed): 1\n",
            "  AUC: 0.5736\n",
            "  F1-Score: 0.2833\n",
            "  Precyzja: 0.2073\n",
            "  Czułość (Recall): 0.4474\n",
            "  Macierz Pomyłek:\n",
            "[[97 65]\n",
            " [21 17]]\n",
            "--- Koniec Pracy nad Modelem: Upsell (Buy Label) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:08:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trening i ewaluacja modelu Churn\n",
        "model_churn = train_evaluate_model_generic(\n",
        "    model_type_name=\"Churn Label\",\n",
        "    X_full=X_source_global.copy(),\n",
        "    y_full=y_churn_source_global,\n",
        "    preprocessor_to_use=preprocessor_global,\n",
        "    cat_features_list=categorical_features_global,\n",
        "    model_output_filename=MODEL_CHURN_FILE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO8H6cTo6kSM",
        "outputId": "2b79dbce-1a15-47e9-9e9d-438ec27e02c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Rozpoczęcie Pracy nad Modelem: Churn Label ---\n",
            "Rozmiar zbioru treningowego: 800, Rozmiar zbioru testowego: 200\n",
            "Liczba cech po przetworzeniu dla Churn Label: 15\n",
            "Przykładowe przetworzone nazwy cech: ['onehot__segment_klinika', 'onehot__segment_mobilny', 'onehot__segment_szpital', 'remainder__clinic_size', 'remainder__devices_owned']...\n",
            "Churn Label - scale_pos_weight: 3.68\n",
            "Trening modelu Churn Label...\n",
            "Trening zakończony.\n",
            "Model Churn Label zapisany do pliku: model_churn.json\n",
            "\n",
            "Ewaluacja modelu Churn Label na zbiorze testowym (używając modelu z 'best_iteration'):\n",
            "  Najlepsza iteracja (0-indexed): 6\n",
            "  AUC: 0.7571\n",
            "  F1-Score: 0.4516\n",
            "  Precyzja: 0.4200\n",
            "  Czułość (Recall): 0.4884\n",
            "  Macierz Pomyłek:\n",
            "[[128  29]\n",
            " [ 22  21]]\n",
            "--- Koniec Pracy nad Modelem: Churn Label ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:08:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Instrukcja Pobierania Plików z Colab ---\n",
        "print(\"\\n\\n--- Zakończono Cały Skrypt ---\")\n",
        "print(f\"Plik danych został zapisany jako '{DATA_FILE_NAME}'.\")\n",
        "print(f\"Modele zostały zapisane jako '{MODEL_UPSELL_FILE}' i '{MODEL_CHURN_FILE}'.\")\n",
        "print(\"Wszystkie te pliki znajdują się w bieżącym środowisku sesji Colab.\")\n",
        "print(\"Aby je pobrać na swój komputer:\")\n",
        "print(\"1. Po lewej stronie w interfejsie Colab kliknij ikonę folderu (Pliki).\")\n",
        "print(\"2. Na liście plików (może być konieczne odświeżenie) znajdź:\")\n",
        "print(f\"   - {DATA_FILE_NAME}\")\n",
        "print(f\"   - {MODEL_UPSELL_FILE}\")\n",
        "print(f\"   - {MODEL_CHURN_FILE}\")\n",
        "print(\"3. Kliknij na trzy kropki obok nazwy każdego pliku i wybierz opcję 'Pobierz'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FunJ2xXO6pi4",
        "outputId": "a399473b-5bc2-4af1-a26d-9af69ed2651e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Zakończono Cały Skrypt ---\n",
            "Plik danych został zapisany jako 'vet_eye_crm_data_1000_PL.csv'.\n",
            "Modele zostały zapisane jako 'model_upsell.json' i 'model_churn.json'.\n",
            "Wszystkie te pliki znajdują się w bieżącym środowisku sesji Colab.\n",
            "Aby je pobrać na swój komputer:\n",
            "1. Po lewej stronie w interfejsie Colab kliknij ikonę folderu (Pliki).\n",
            "2. Na liście plików (może być konieczne odświeżenie) znajdź:\n",
            "   - vet_eye_crm_data_1000_PL.csv\n",
            "   - model_upsell.json\n",
            "   - model_churn.json\n",
            "3. Kliknij na trzy kropki obok nazwy każdego pliku i wybierz opcję 'Pobierz'.\n"
          ]
        }
      ]
    }
  ]
}