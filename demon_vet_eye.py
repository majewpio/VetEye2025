import streamlit as st
import pandas as pd
import numpy as np
import xgboost
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.base import clone # Potrzebne do klonowania preprocessora

# --- Konfiguracja Nazw Plik√≥w ---
DATA_FILE = "vet_eye_crm_data_1000_PL.csv"
MODEL_UPSELL_FILE = "model_upsell.json"
MODEL_CHURN_FILE = "model_churn.json"

# --- Funkcje Pomocnicze ---

@st.cache_data # Cache'owanie wczytanych danych
def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        # Sprawdzenie, czy kluczowe kolumny istniejƒÖ
        required_cols = ['client_id', 'segment', 'buy_label', 'churn_label'] # Dodaj inne, je≈õli sƒÖ krytyczne
        if not all(col in df.columns for col in required_cols):
            st.error(f"B≈ÅƒÑD: W pliku danych '{file_path}' brakuje jednej z wymaganych kolumn: {required_cols}.")
            return None
        return df
    except FileNotFoundError:
        st.error(f"B≈ÅƒÑD: Nie znaleziono pliku danych '{file_path}'. Upewnij siƒô, ≈ºe plik jest w repozytorium.")
        return None
    except Exception as e:
        st.error(f"B≈ÅƒÑD: Nieoczekiwany problem przy wczytywaniu danych z '{file_path}'. Szczeg√≥≈Çy: {e}")
        return None


@st.cache_resource # Cache'owanie wczytanych modeli
def load_xgb_model(file_path):
    try:
        model = xgboost.XGBClassifier()
        model.load_model(file_path)
        return model
    except Exception as e:
        st.error(f"B≈ÅƒÑD: Nie mo≈ºna wczytaƒá modelu z '{file_path}'. Szczeg√≥≈Çy: {e}")
        return None

@st.cache_resource # Cache'owanie dopasowanego preprocessora
def get_and_fit_preprocessor(_df_for_fitting): # Podkre≈õlenie, ≈ºe df jest tylko do fitowania
    """
    Definiuje i dopasowuje preprocessor (ColumnTransformer) na podstawie dostarczonego DataFrame.
    """
    categorical_features = ['segment']
    if not all(feature in _df_for_fitting.columns for feature in categorical_features):
        st.error("B≈ÇƒÖd: W danych brakuje kolumny 'segment' potrzebnej do preprocessingu.")
        return None
        
    preprocessor = ColumnTransformer(
        transformers=[
            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='passthrough' 
    )
    try:
        # U≈ºywamy kopii df_for_fitting do fitowania, aby uniknƒÖƒá modyfikacji orygina≈Çu, je≈õli by≈Çby u≈ºywany gdzie≈õ indziej
        # Usuwamy kolumny, kt√≥re nie sƒÖ cechami modelu (zak≈Çadamy, ≈ºe sƒÖ obecne w _df_for_fitting)
        df_fit_features = _df_for_fitting.drop(columns=['client_id', 'buy_label', 'churn_label'], errors='ignore')
        preprocessor.fit(df_fit_features)
        return preprocessor
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas dopasowywania preprocessora: {e}")
        return None

def get_simplified_feature_influence(client_features_processed_df, model, top_n=3):
    """
    Zwraca uproszczony opis wp≈Çywu cech na podstawie og√≥lnej wa≈ºno≈õci cech modelu
    i warto≈õci cech danego klienta. To NIE jest SHAP, tylko heurystyka.
    """
    try:
        importances = model.feature_importances_
        # Zak≈Çadamy, ≈ºe client_features_processed_df ma nazwy kolumn odpowiadajƒÖce kolejno≈õci w importances
        # lub ≈ºe model zosta≈Ç wytrenowany z feature_names.
        # Dla uproszczenia, je≈õli model nie ma feature_names_in_, spr√≥bujemy u≈ºyƒá kolumn z przetworzonego df.
        if hasattr(model, 'feature_names_in_'):
            feature_names = model.feature_names_in_
        elif client_features_processed_df is not None and hasattr(client_features_processed_df, 'columns'):
             feature_names = client_features_processed_df.columns
        else: # Fallback, je≈õli nie mamy nazw cech
            feature_names = [f"Cecha_{i}" for i in range(len(importances))]


        feature_importance_map = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)
        
        influential_features_text = []
        for feature_name, importance_score in feature_importance_map[:top_n]:
            # Mapowanie przetworzonej nazwy cechy na bardziej czytelnƒÖ, je≈õli to mo≈ºliwe
            # To wymaga≈Çoby dodatkowej logiki mapowania (np. z one-hot na oryginalnƒÖ kategoriƒô)
            # Na razie u≈ºyjemy przetworzonej nazwy
            
            # Sprawdzenie warto≈õci tej cechy dla klienta
            client_value_text = ""
            if client_features_processed_df is not None and feature_name in client_features_processed_df.columns:
                client_val = client_features_processed_df[feature_name].iloc[0]
                # Prosta interpretacja (mo≈ºna rozbudowaƒá)
                if client_val > 0.5 and client_val <=1: # Dla cech binarnych lub znormalizowanych
                    client_value_text = " (wysoka warto≈õƒá u klienta)"
                elif client_val == 0 or (client_val <0.5 and client_val >=0) : # Dla cech binarnych lub znormalizowanych
                    client_value_text = " (niska warto≈õƒá u klienta)"
                elif client_val > 1: # Dla cech numerycznych
                     client_value_text = f" (warto≈õƒá: {client_val:.2f})"


            influential_features_text.append(f"- **{feature_name.replace('onehot__segment_', 'Segment: ').replace('remainder__', '')}**{client_value_text}")
        
        if influential_features_text:
            return "Prawdopodobne kluczowe czynniki wp≈ÇywajƒÖce na scoring (og√≥lna wa≈ºno≈õƒá cech):\n" + "\n".join(influential_features_text)
        else:
            return "Analiza wp≈Çywu poszczeg√≥lnych cech nie jest dostƒôpna."

    except Exception as e:
        # st.warning(f"Nie mo≈ºna by≈Ço wygenerowaƒá uproszczonego wp≈Çywu cech: {e}")
        return "Analiza wp≈Çywu poszczeg√≥lnych cech nie jest obecnie dostƒôpna."


def get_recommendations(buy_score_proba, churn_score_proba, segment, client_id=""):
    """Generuje proste rekomendacje na podstawie scoring√≥w i segmentu."""
    recs = []
    buy_prob_percent = buy_score_proba * 100
    churn_prob_percent = churn_score_proba * 100

    recs.append(f"**Klient {client_id}:**")
    # Rekomendacje Upsell
    if buy_prob_percent > 70: # Zmieniony pr√≥g dla wiƒôkszej selektywno≈õci
        recs.append(f"üî• **Wysoki Potencja≈Ç Zakupowy ({buy_prob_percent:.0f}%)!** Rozwa≈º pilny kontakt z ofertƒÖ premium.")
        if segment == "szpital":
            recs.append("   - Zaproponuj najnowszy model USG VetEye ProMax z pakietem g≈Çowic specjalistycznych.")
            recs.append("   - Zaoferuj dedykowane szkolenie dla personelu szpitala.")
        elif segment == "klinika":
            recs.append("   - Zaproponuj rozszerzenie obecnego sprzƒôtu o dodatkowƒÖ g≈Çowicƒô TU2-Cardio lub TU2-Endo.")
            recs.append("   - Poinformuj o nowej wersji platformy TU2 AI z zaawansowanƒÖ analizƒÖ obrazu i mo≈ºliwo≈õciƒÖ konsultacji zdalnych.")
        else: # mobilny
            recs.append("   - Zaproponuj lekki i wytrzyma≈Çy model VetEye Portable 15 z nowƒÖ, wydajniejszƒÖ bateriƒÖ i specjalnym etui.")
    elif buy_prob_percent > 45: # Zmieniony pr√≥g
        recs.append(f"üí° **≈öredni Potencja≈Ç Zakupowy ({buy_prob_percent:.0f}%)!** Dobry moment na ofertƒô rozszerzajƒÖcƒÖ lub budowanie relacji.")
        recs.append("   - Wy≈õlij e-mail z informacjƒÖ o promocji na materia≈Çy eksploatacyjne, akcesoria lub nadchodzƒÖcy webinar tematyczny.")
        recs.append("   - Zaproponuj kr√≥tkƒÖ rozmowƒô telefonicznƒÖ w celu zbadania aktualnych potrzeb.")
    else:
        recs.append(f"‚ÑπÔ∏è Niski Potencja≈Ç Zakupowy ({buy_prob_percent:.0f}%). Skup siƒô na utrzymaniu dobrej relacji i monitoringu.")

    # Rekomendacje Antychurn
    if churn_prob_percent > 65: # Zmieniony pr√≥g
        recs.append(f"üö® **Bardzo Wysokie Ryzyko Rezygnacji ({churn_prob_percent:.0f}%)!** Wymagane natychmiastowe dzia≈Çania utrzymaniowe!")
        recs.append("   - Osobisty telefon od opiekuna klienta w celu zdiagnozowania problemu i okazania wsparcia.")
        recs.append("   - Zaproponuj specjalne, indywidualne warunki odnowienia subskrypcji lub pakiet dodatkowego wsparcia technicznego/szkoleniowego.")
        recs.append("   - Przeanalizuj dok≈Çadnie historiƒô kontakt√≥w i zg≈Çosze≈Ñ, aby zrozumieƒá przyczynƒô.")
    elif churn_prob_percent > 35: # Zmieniony pr√≥g
        recs.append(f"‚ö†Ô∏è **Podwy≈ºszone Ryzyko Rezygnacji ({churn_prob_percent:.0f}%)!** Zaplanuj dzia≈Çania prewencyjne.")
        recs.append("   - Zapro≈õ na bezp≈Çatny webinar dotyczƒÖcy nowych funkcji platformy TU2 lub warsztat podnoszƒÖcy umiejƒôtno≈õci.")
        recs.append("   - Wy≈õlij warto≈õciowe materia≈Çy edukacyjne lub case studies pokazujƒÖce korzy≈õci z produkt√≥w/us≈Çug Vet-Eye.")
        recs.append("   - Rozwa≈º proaktywny kontakt w celu zebrania feedbacku i zaoferowania pomocy.")
    else:
        recs.append(f"üëç Niskie Ryzyko Rezygnacji ({churn_prob_percent:.0f}%). Utrzymuj standardowy, dobry kontakt.")
    
    recs.append("\n*Pamiƒôtaj, to sƒÖ sugestie systemu AI oparte na danych. Ostateczna decyzja i forma dzia≈Çania nale≈ºƒÖ do Ciebie.*")
    return recs

# --- G≈Ç√≥wna Aplikacja Streamlit ---
st.set_page_config(page_title="Vet-Eye AI Scoring POC", layout="wide")
st.title("üêæ Vet-Eye S.A. - Demonstrator Systemu Scoringowego AI")
st.markdown("Wersja Proof of Concept wspierajƒÖca decyzje handlowe.")

# Wczytanie danych i modeli
df_crm_global = load_data(DATA_FILE)
model_upsell_global = load_xgb_model(MODEL_UPSELL_FILE)
model_churn_global = load_xgb_model(MODEL_CHURN_FILE)
preprocessor_global_fitted = None # Zostanie zainicjalizowany po wczytaniu df_crm_global

if df_crm_global is not None:
    df_features_for_preprocessor_fit = df_crm_global.drop(columns=['client_id', 'buy_label', 'churn_label'], errors='ignore')
    if not df_features_for_preprocessor_fit.empty:
         preprocessor_global_fitted = get_and_fit_preprocessor(df_features_for_preprocessor_fit.copy()) # U≈ºywamy kopii

# --- Definicja Zak≈Çadek ---
if df_crm_global is not None and model_upsell_global is not None and model_churn_global is not None and preprocessor_global_fitted is not None:
    
    # Obliczanie scoring√≥w dla wszystkich klient√≥w (do sortowania)
    # Przygotowujemy dane wszystkich klient√≥w do predykcji
    df_clients_features = df_crm_global.drop(columns=['client_id', 'buy_label', 'churn_label'], errors='ignore')
    
    # Sprawdzenie, czy preprocessor zosta≈Ç poprawnie dopasowany
    try:
        clients_data_processed = preprocessor_global_fitted.transform(df_clients_features)
        
        # Dodanie nazw kolumn do przetworzonych danych, je≈õli to mo≈ºliwe
        # To pomo≈ºe w funkcji get_simplified_feature_influence, je≈õli model nie ma feature_names_in_
        try:
            processed_cols = list(preprocessor_global_fitted.get_feature_names_out())
            clients_data_processed_df = pd.DataFrame(clients_data_processed, columns=processed_cols, index=df_clients_features.index)
        except: # Fallback
            clients_data_processed_df = pd.DataFrame(clients_data_processed, index=df_clients_features.index)


        df_crm_global['buy_score_proba'] = model_upsell_global.predict_proba(clients_data_processed)[:, 1]
        df_crm_global['churn_score_proba'] = model_churn_global.predict_proba(clients_data_processed)[:, 1]
        
        # Dodanie czytelnych etykiet scoringu
        def get_buy_score_label(score):
            if score > 0.7: return "Wysoki Potencja≈Ç"
            if score > 0.45: return "≈öredni Potencja≈Ç"
            return "Niski Potencja≈Ç"
        
        def get_churn_score_label(score):
            if score > 0.65: return "Wysokie Ryzyko"
            if score > 0.35: return "≈örednie Ryzyko"
            return "Niskie Ryzyko"

        df_crm_global['buy_score_label'] = df_crm_global['buy_score_proba'].apply(get_buy_score_label)
        df_crm_global['churn_score_label'] = df_crm_global['churn_score_proba'].apply(get_churn_score_label)


        tab1_title = "üìà Modu≈Ç Sprzeda≈ºowy (Upsell)"
        tab2_title = "üõ°Ô∏è Modu≈Ç Antychurnowy"
        tab3_title = "üë§ Szczeg√≥≈Çy Klienta"

        tab1, tab2, tab3 = st.tabs([tab1_title, tab2_title, tab3_title])

        with tab1:
            st.header(tab1_title)
            st.markdown("Lista klient√≥w posortowana wed≈Çug potencja≈Çu na dosprzeda≈º (najwy≈ºszy na g√≥rze).")
            df_upsell_sorted = df_crm_global.sort_values(by='buy_score_proba', ascending=False)
            st.dataframe(df_upsell_sorted[['client_id', 'segment', 'clinic_size', 'buy_score_proba', 'buy_score_label', 'churn_score_proba', 'churn_score_label']].rename(columns={
                'client_id': 'ID Klienta', 'segment': 'Segment', 'clinic_size': 'Wielko≈õƒá Kliniki',
                'buy_score_proba': 'Potencja≈Ç Zakupowy (%)', 'buy_score_label': 'Ocena Potencja≈Çu',
                'churn_score_proba': 'Ryzyko Churn (%)', 'churn_score_label': 'Ocena Ryzyka Churn'
            }).style.format({'Potencja≈Ç Zakupowy (%)': '{:.1%}', 'Ryzyko Churn (%)': '{:.1%}'}), height=500)

        with tab2:
            st.header(tab2_title)
            st.markdown("Lista klient√≥w posortowana wed≈Çug ryzyka rezygnacji (najwy≈ºsze na g√≥rze).")
            df_churn_sorted = df_crm_global.sort_values(by='churn_score_proba', ascending=False)
            st.dataframe(df_churn_sorted[['client_id', 'segment', 'clinic_size', 'churn_score_proba', 'churn_score_label', 'buy_score_proba', 'buy_score_label']].rename(columns={
                'client_id': 'ID Klienta', 'segment': 'Segment', 'clinic_size': 'Wielko≈õƒá Kliniki',
                'churn_score_proba': 'Ryzyko Churn (%)', 'churn_score_label': 'Ocena Ryzyka Churn',
                'buy_score_proba': 'Potencja≈Ç Zakupowy (%)', 'buy_score_label': 'Ocena Potencja≈Çu'
            }).style.format({'Ryzyko Churn (%)': '{:.1%}', 'Potencja≈Ç Zakupowy (%)': '{:.1%}'}), height=500)

        with tab3:
            st.header(tab3_title)
            st.markdown("Wybierz klienta z poni≈ºszej listy, aby zobaczyƒá szczeg√≥≈ÇowƒÖ analizƒô i rekomendacje.")
            
            client_id_list = df_crm_global['client_id'].tolist()
            selected_client_id_tab3 = st.selectbox(
                "Wybierz ID Klienta:",
                options=client_id_list,
                index=0, # Domy≈õlnie pierwszy klient
                key="client_selector_tab3"
            )
            
            client_data_row = df_crm_global[df_crm_global['client_id'] == selected_client_id_tab3].iloc[0:1]

            if not client_data_row.empty:
                buy_score_proba_selected = client_data_row['buy_score_proba'].iloc[0]
                churn_score_proba_selected = client_data_row['churn_score_proba'].iloc[0]
                segment_selected = client_data_row['segment'].iloc[0]

                col1_detail, col2_detail = st.columns(2)
                with col1_detail:
                    st.metric(label="Potencja≈Ç Zakupowy (30 dni)", value=f"{buy_score_proba_selected*100:.1f}%")
                    st.markdown(f"**Ocena:** {client_data_row['buy_score_label'].iloc[0]}")
                
                with col2_detail:
                    st.metric(label="Ryzyko Rezygnacji (Churn)", value=f"{churn_score_proba_selected*100:.1f}%")
                    st.markdown(f"**Ocena:** {client_data_row['churn_score_label'].iloc[0]}")

                st.markdown("---")
                st.subheader("Sugerowane Dzia≈Çania (System AI Vet-Eye):")
                recommendations = get_recommendations(buy_score_proba_selected, churn_score_proba_selected, segment_selected, selected_client_id_tab3)
                for rec in recommendations:
                    st.markdown(rec)

                st.markdown("---")
                st.subheader("Uproszczona Analiza Wp≈Çywu Cech:")
                # Przygotowanie danych klienta do analizy wp≈Çywu cech (potrzebuje przetworzonych danych)
                client_features_for_influence = df_clients_features[df_clients_features.index == client_data_row.index[0]]
                # U≈ºywamy tej samej logiki, co przy predykcjach dla wszystkich klient√≥w
                if hasattr(preprocessor_global_fitted, 'transform'): # Sprawdzenie czy preprocessor jest gotowy
                    client_data_processed_single_df = pd.DataFrame(
                        preprocessor_global_fitted.transform(client_features_for_influence),
                        columns=clients_data_processed_df.columns # U≈ºywamy kolumn z przetworzonego zbioru
                    )
                    
                    st.markdown("##### Dla Potencja≈Çu Zakupowego:")
                    st.markdown(get_simplified_feature_influence(client_data_processed_single_df, model_upsell_global))
                    st.markdown("##### Dla Ryzyka Rezygnacji:")
                    st.markdown(get_simplified_feature_influence(client_data_processed_single_df, model_churn_global))
                else:
                    st.warning("Preprocessor nie zosta≈Ç poprawnie zainicjalizowany do analizy wp≈Çywu cech.")


                st.markdown("---")
                st.subheader("Dane Klienta (z symulowanego CRM):")
                display_data = {
                    "ID Klienta": client_data_row['client_id'].iloc[0],
                    "Segment Rynku": segment_selected,
                    "Wielko≈õƒá Kliniki (personel)": client_data_row['clinic_size'].iloc[0],
                    "Liczba Posiadanych UrzƒÖdze≈Ñ Vet-Eye": client_data_row['devices_owned'].iloc[0],
                    "Dni od Ostatniego Zakupu": client_data_row['last_purchase_days_ago'].iloc[0],
                    "≈ÅƒÖczna Liczba Zakup√≥w": client_data_row['purchase_count'].iloc[0],
                    "≈örednia Warto≈õƒá Zakupu (PLN)": f"{client_data_row['avg_purchase_value'].iloc[0]:.2f}",
                    "Aktywna Subskrypcja TU2": "Tak" if client_data_row['tu2_active'].iloc[0] == 1 else "Nie",
                    "Liczba Sesji TU2 (ost. 30 dni)": client_data_row['tu2_sessions_last_30d'].iloc[0],
                    "Wykorzystanie Modu≈Ç√≥w AI w TU2 (%)": f"{client_data_row['ai_usage_ratio'].iloc[0]*100:.0f}%",
                    "Dni od Ostatniego Kontaktu Handlowego": client_data_row['last_contact_days_ago'].iloc[0],
                    "Wska≈∫nik Otwarƒá E-maili (%)": f"{client_data_row['open_rate'].iloc[0]*100:.0f}%",
                    "Wska≈∫nik Klikniƒôƒá w E-mailach (%)": f"{client_data_row['click_rate'].iloc[0]*100:.0f}%",
                    "Liczba Zg≈Çosze≈Ñ Serwisowych (ost. 6 m-cy)": client_data_row['support_tickets_last_6m'].iloc[0]
                }
                for key, value in display_data.items():
                    st.markdown(f"**{key}:** {value}")

    except Exception as e:
        st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd podczas przetwarzania danych dla wszystkich klient√≥w lub predykcji: {e}")
        st.error("Sprawd≈∫ logi i konfiguracjƒô preprocessora.")

else:
    st.error("Nie uda≈Ço siƒô wczytaƒá danych CRM lub modeli. Aplikacja nie mo≈ºe kontynuowaƒá.")
    st.warning("Upewnij siƒô, ≈ºe pliki `vet_eye_crm_data_1000_PL.csv`, `model_upsell.json` oraz `model_churn.json` znajdujƒÖ siƒô w g≈Ç√≥wnym katalogu repozytorium GitHub.")

st.sidebar.markdown("---")
st.sidebar.info("To jest aplikacja demonstracyjna (POC) systemu scoringowego AI firmy Vet-Eye S.A. Wersja ulepszona z zak≈Çadkami.")